@article{Abd-Alrazaq2019Overview,
    title = {An Overview of the Features of Chatbots in Mental Health: A scoping Review},
    journal = {International Journal of Medical Informatics},
    volume = {132},
    references = {Vaidyam2019Chatbots Inkster2018Empathy Fitzpatrick2017Cognitive},
    pages = {103978},
    year = {2019},
    issn = {1386-5056},
    doi = {https://doi.org/10.1016/j.ijmedinf.2019.103978},
    url = {https://www.sciencedirect.com/science/article/pii/S1386505619307166},
    author = {Abd-Alrazaq, Alaa Ali and Alajlani, Mohannad and Alalwan, Ali Abdallah and Bewick, Bridgette M and Gardner, Peter and Househ, Mowafa},
    keywords = {type: Article, Chatbots, Conversational agents, Mental health, Mental disorders, Depression},
    abstract = {Background
Chatbots are systems that are able to converse and interact with human users using spoken, written, and visual languages. Chatbots have the potential to be useful tools for individuals with mental disorders, especially those who are reluctant to seek mental health advice due to stigmatization. While numerous studies have been conducted about using chatbots for mental health, there is a need to systematically bring this evidence together in order to inform mental health providers and potential users about the main features of chatbots and their potential uses, and to inform future research about the main gaps of the previous literature.
Objective
We aimed to provide an overview of the features of chatbots used by individuals for their mental health as reported in the empirical literature.
Methods
Seven bibliographic databases (Medline, Embase, PsycINFO, Cochrane Central Register of Controlled Trials, IEEE Xplore, ACM Digital Library, and Google Scholar) were used in our search. In addition, backward and forward reference list checking of the included studies and relevant reviews was conducted. Study selection and data extraction were carried out by two reviewers independently. Extracted data were synthesised using a narrative approach. Chatbots were classified according to their purposes, platforms, response generation, dialogue initiative, input and output modalities, embodiment, and targeted disorders.
Results
Of 1039 citations retrieved, 53 unique studies were included in this review. The included studies assessed 41 different chatbots. Common uses of chatbots were: therapy (n = 17), training (n = 12), and screening (n = 10). Chatbots in most studies were rule-based (n = 49) and implemented in stand-alone software (n = 37). In 46 studies, chatbots controlled and led the conversations. While the most frequently used input modality was written language only (n = 26), the most frequently used output modality was a combination of written, spoken and visual languages (n = 28). In the majority of studies, chatbots included virtual representations (n = 44). The most common focus of chatbots was depression (n = 16) or autism (n = 10).
Conclusion
Research regarding chatbots in mental health is nascent. There are numerous chatbots that are used for various mental disorders and purposes. Healthcare providers should compare chatbots found in this review to help guide potential users to the most appropriate chatbot to support their mental health needs. More reviews are needed to summarise the evidence regarding the effectiveness and acceptability of chatbots in mental health.}
}

@article{Abd-Alrazaq2020Effectiveness,
    author = {Abd-Alrazaq, Alaa Ali and Rababeh, Asma and Alajlani, Mohannad and Bewick, Bridgette M and Househ, Mowafa},
    title = {Effectiveness and Safety of Using Chatbots to Improve Mental Health: Systematic Review and Meta-Analysis},
    journal = {J Med Internet Res},
    references = {Abd-Alrazaq2019Overview Vaidyam2019Chatbots Palanica2019Physicians Inkster2018Empathy Fulmer2018Psychological Ly2017Automated Fitzpatrick2017Cognitive},
    year = {2020},
    month = {Jul},
    day = {13},
    volume = {22},
    number = {7},
    pages = {e16021},
    keywords = {type: Article, Chatbots, conversational agents, mental health, mental disorders, depression, anxiety, effectiveness, safety},
    abstract = {Background: The global shortage of mental health workers has prompted the utilization of technological advancements, such as chatbots, to meet the needs of people with mental health conditions. Chatbots are systems that are able to converse and interact with human users using spoken, written, and visual language. While numerous studies have assessed the effectiveness and safety of using chatbots in mental health, no reviews have pooled the results of those studies. Objective: This study aimed to assess the effectiveness and safety of using chatbots to improve mental health through summarizing and pooling the results of previous studies. Methods: A systematic review was carried out to achieve this objective. The search sources were 7 bibliographic databases (eg, MEDLINE, EMBASE, PsycINFO), the search engine ``Google Scholar,'' and backward and forward reference list checking of the included studies and relevant reviews. Two reviewers independently selected the studies, extracted data from the included studies, and assessed the risk of bias. Data extracted from studies were synthesized using narrative and statistical methods, as appropriate. Results: Of 1048 citations retrieved, we identified 12 studies examining the effect of using chatbots on 8 outcomes. Weak evidence demonstrated that chatbots were effective in improving depression, distress, stress, and acrophobia. In contrast, according to similar evidence, there was no statistically significant effect of using chatbots on subjective psychological wellbeing. Results were conflicting regarding the effect of chatbots on the severity of anxiety and positive and negative affect. Only two studies assessed the safety of chatbots and concluded that they are safe in mental health, as no adverse events or harms were reported. Conclusions: Chatbots have the potential to improve mental health. However, the evidence in this review was not sufficient to definitely conclude this due to lack of evidence that their effect is clinically important, a lack of studies assessing each outcome, high risk of bias in those studies, and conflicting results for some outcomes. Further studies are required to draw solid conclusions about the effectiveness and safety of chatbots. Trial Registration: PROSPERO International Prospective Register of Systematic Reviews CRD42019141219; https://www.crd.york.ac.uk/prospero/display{\_}record.php?ID=CRD42019141219 },
    issn = {1438-8871},
    doi = {10.2196/16021},
    url = {http://www.jmir.org/2020/7/e16021/},
    url = {https://doi.org/10.2196/16021},
    url = {http://www.ncbi.nlm.nih.gov/pubmed/32673216}
}

@article{Bendig2018Interventions,
    author = {Bendig, Eileen and Bauereiß, Natalie and Ebert, David Daniel and Snoek, Frank and Andersson, Gerhard and Baumeister, Harald},
    title = {{Internet-Based Interventions in Chronic Somatic Disease}},
    journal = {Dtsch Arztebl International},
    volume = {115},
    number = {40},
    pages = {659-665},
    doi = {10.3238/arztebl.2018.0659},
    year = {2018},
    keywords = {type: Article},
    abstract = {Background: Clinical guidelines recommend psychosocial care as an integral part of medical treatment, but access is often limited. Technology-based approaches provide an attractive opportunity to optimize health outcomes and quality of life in people with chronic somatic diseases e.g. by means of Internet- and mobile-based interventions (IMIs). The present article provides an overview on the basics of IMIs, applications and their evidence base for people living with chronic somatic diseases.Methods: We conducted a selective literature search in the PubMed and Cochrane databases. Reviews which included randomized controlled trials investigating psychological IMIs were discussed pertaining to their relevance for the population described.Results: IMIs lead to a change in unfavorable behavior connected to chronic somatic diseases. IMIs can foster protective factors like balanced physical activity or risk factors like smoking or alcohol consumption. However, studies reveal small effect sizes of d=0.25 for physical activity and an averaged effect size of d=0.20 for smoking and alcohol consumption. Additionally, IMIs can be used for the (co-)treatment of chronic somatic diseases, for instance to increase disease-specific self-efficacy in patients with diabetes (d=0.23). Studies included in meta-analyses are often highly heterogenous and are investigated in research contexts with limited health care services relevance.Conclusion: IMIs are potentially effective when aiming at lifestyle changes and supporting medical treatment in people with chronic somatic diseases. However, results are still heterogenous and the evidence base is limited regarding specific settings, compounding the discussion of possible ways of implementing IMIs into our health-care systems.},
    URL = {https://www.aerzteblatt.de/int/article.asp?id=201079},
    eprint = {https://www.aerzteblatt.de/pdf.asp?id=201079}
}


@article{Fitzpatrick2017Cognitive,
    author = {Fitzpatrick, Kathleen Kara
and Darcy, Alison
and Vierhile, Molly},
    title = {Delivering Cognitive Behavior Therapy to Young Adults With Symptoms of Depression and Anxiety Using a Fully Automated Conversational Agent (Woebot): A Randomized Controlled Trial},
    journal = {JMIR Ment Health},
    year = {2017},
    month = {Jun},
    day = {06},
    volume = {4},
    number = {2},
    pages = {e19},
    keywords = {type: article, conversational agents, mobile mental health, mental health, chatbots, depression, anxiety, college students, digital health},
    abstract = {Background: Web-based cognitive-behavioral therapeutic (CBT) apps have demonstrated efficacy but are characterized by poor adherence. Conversational agents may offer a convenient, engaging way of getting support at any time. Objective: The objective of the study was to determine the feasibility, acceptability, and preliminary efficacy of a fully automated conversational agent to deliver a self-help program for college students who self-identify as having symptoms of anxiety and depression. Methods: In an unblinded trial, 70 individuals age 18-28 years were recruited online from a university community social media site and were randomized to receive either 2 weeks (up to 20 sessions) of self-help content derived from CBT principles in a conversational format with a text-based conversational agent (Woebot) (n=34) or were directed to the National Institute of Mental Health ebook, ``Depression in College Students,'' as an information-only control group (n=36). All participants completed Web-based versions of the 9-item Patient Health Questionnaire (PHQ-9), the 7-item Generalized Anxiety Disorder scale (GAD-7), and the Positive and Negative Affect Scale at baseline and 2-3 weeks later (T2). Results: Participants were on average 22.2 years old (SD 2.33), 67{\%} female (47/70), mostly non-Hispanic (93{\%}, 54/58), and Caucasian (79{\%}, 46/58). Participants in the Woebot group engaged with the conversational agent an average of 12.14 (SD 2.23) times over the study period. No significant differences existed between the groups at baseline, and 83{\%} (58/70) of participants provided data at T2 (17{\%} attrition). Intent-to-treat univariate analysis of covariance revealed a significant group difference on depression such that those in the Woebot group significantly reduced their symptoms of depression over the study period as measured by the PHQ-9 (F=6.47; P=.01) while those in the information control group did not. In an analysis of completers, participants in both groups significantly reduced anxiety as measured by the GAD-7 (F1,54= 9.24; P=.004). Participants' comments suggest that process factors were more influential on their acceptability of the program than content factors mirroring traditional therapy. Conclusions: Conversational agents appear to be a feasible, engaging, and effective way to deliver CBT. },
    issn = {2368-7959},
    doi = {10.2196/mental.7785},
    url = {http://mental.jmir.org/2017/2/e19/},
    url = {https://doi.org/10.2196/mental.7785},
    url = {http://www.ncbi.nlm.nih.gov/pubmed/28588005}
}

@article{Fulmer2018Psychological,
    author = {Fulmer, Russell
and Joerin, Angela
and Gentile, Breanna
and Lakerink, Lysanne
and Rauws, Michiel},
    title = {Using Psychological Artificial Intelligence (Tess) to Relieve Symptoms of Depression and Anxiety: Randomized Controlled Trial},
    journal = {JMIR Ment Health},
    references = {Fitzpatrick2017Cognitive},
    year = {2018},
    month = {Dec},
    day = {13},
    volume = {5},
    number = {4},
    pages = {e64},
    keywords = {type: article, artificial intelligence, mental health services, depression, anxiety, students},
    abstract = {Background: Students in need of mental health care face many barriers including cost, location, availability, and stigma. Studies show that computer-assisted therapy and 1 conversational chatbot delivering cognitive behavioral therapy (CBT) offer a less-intensive and more cost-effective alternative for treating depression and anxiety. Although CBT is one of the most effective treatment methods, applying an integrative approach has been linked to equally effective posttreatment improvement. Integrative psychological artificial intelligence (AI) offers a scalable solution as the demand for affordable, convenient, lasting, and secure support grows. Objective: This study aimed to assess the feasibility and efficacy of using an integrative psychological AI, Tess, to reduce self-identified symptoms of depression and anxiety in college students. Methods: In this randomized controlled trial, 75 participants were recruited from 15 universities across the United States. All participants completed Web-based surveys, including the Patient Health Questionnaire (PHQ-9), Generalized Anxiety Disorder Scale (GAD-7), and Positive and Negative Affect Scale (PANAS) at baseline and 2 to 4 weeks later (T2). The 2 test groups consisted of 50 participants in total and were randomized to receive unlimited access to Tess for either 2 weeks (n=24) or 4 weeks (n=26). The information-only control group participants (n=24) received an electronic link to the National Institute of Mental Health's (NIMH) eBook on depression among college students and were only granted access to Tess after completion of the study. Results: A sample of 74 participants completed this study with 0{\%} attrition from the test group and less than 1{\%} attrition from the control group (1/24). The average age of participants was 22.9 years, with 70{\%} of participants being female (52/74), mostly Asian (37/74, 51{\%}), and white (32/74, 41{\%}). Group 1 received unlimited access to Tess, with daily check-ins for 2 weeks. Group 2 received unlimited access to Tess with biweekly check-ins for 4 weeks. The information-only control group was provided with an electronic link to the NIMH's eBook. Multivariate analysis of covariance was conducted. We used an alpha level of .05 for all statistical tests. Results revealed a statistically significant difference between the control group and group 1, such that group 1 reported a significant reduction in symptoms of depression as measured by the PHQ-9 (P=.03), whereas those in the control group did not. A statistically significant difference was found between the control group and both test groups 1 and 2 for symptoms of anxiety as measured by the GAD-7. Group 1 (P=.045) and group 2 (P=.02) reported a significant reduction in symptoms of anxiety, whereas the control group did not. A statistically significant difference was found on the PANAS between the control group and group 1 (P=.03) and suggests that Tess did impact scores. Conclusions: This study offers evidence that AI can serve as a cost-effective and accessible therapeutic agent. Although not designed to appropriate the role of a trained therapist, integrative psychological AI emerges as a feasible option for delivering support. Trial Registration: International Standard Randomized Controlled Trial Number: ISRCTN61214172; https://doi.org/10.1186/ISRCTN61214172. },
    issn = {2368-7959},
    doi = {10.2196/mental.9782},
    url = {http://mental.jmir.org/2018/4/e64/},
    url = {https://doi.org/10.2196/mental.9782},
    url = {http://www.ncbi.nlm.nih.gov/pubmed/30545815}
}

@article{Gaffney2019Conversational,
    author = {Gaffney, Hannah
and Mansell, Warren
and Tai, Sara},
    title = {Conversational Agents in the Treatment of Mental Health Problems: Mixed-Method Systematic Review},
    journal = {JMIR Ment Health},
    references = {Inkster2018Empathy Fulmer2018Psychological Ly2017Automated Fitzpatrick2017Cognitive},
    year = {2019},
    month = {Oct},
    day = {18},
    volume = {6},
    number = {10},
    pages = {e14166},
    keywords = {type: article, artificial intelligence, mental health, stress, pychological, psychiatry, therapy, computer-assisted conversational agent, chatbot, digital health},
    abstract = {Background: The use of conversational agent interventions (including chatbots and robots) in mental health is growing at a fast pace. Recent existing reviews have focused exclusively on a subset of embodied conversational agent interventions despite other modalities aiming to achieve the common goal of improved mental health. Objective: This study aimed to review the use of conversational agent interventions in the treatment of mental health problems. Methods: We performed a systematic search using relevant databases (MEDLINE, EMBASE, PsycINFO, Web of Science, and Cochrane library). Studies that reported on an autonomous conversational agent that simulated conversation and reported on a mental health outcome were included. Results: A total of 13 studies were included in the review. Among them, 4 full-scale randomized controlled trials (RCTs) were included. The rest were feasibility, pilot RCTs and quasi-experimental studies. Interventions were diverse in design and targeted a range of mental health problems using a wide variety of therapeutic orientations. All included studies reported reductions in psychological distress postintervention. Furthermore, 5 controlled studies demonstrated significant reductions in psychological distress compared with inactive control groups. In addition, 3 controlled studies comparing interventions with active control groups failed to demonstrate superior effects. Broader utility in promoting well-being in nonclinical populations was unclear. Conclusions: The efficacy and acceptability of conversational agent interventions for mental health problems are promising. However, a more robust experimental design is required to demonstrate efficacy and efficiency. A focus on streamlining interventions, demonstrating equivalence to other treatment modalities, and elucidating mechanisms of action has the potential to increase acceptance by users and clinicians and maximize reach. },
    issn = {2368-7959},
    doi = {10.2196/14166},
    url = {https://mental.jmir.org/2019/10/e14166},
    url = {https://doi.org/10.2196/14166},
    url = {http://www.ncbi.nlm.nih.gov/pubmed/31628789}
}

@article{Inkster2018Empathy,
    author = {Inkster, Becky
and Sarda, Shubhankar
and Subramanian, Vinod},
    title = {An Empathy-Driven, Conversational Artificial Intelligence Agent (Wysa) for Digital Mental Well-Being: Real-World Data Evaluation Mixed-Methods Study},
    journal = {JMIR Mhealth Uhealth},
    references = {Ly2017Automated Fitzpatrick2017Cognitive},
    year = {2018},
    month = {Nov},
    day = {23},
    volume = {6},
    number = {11},
    pages = {e12106},
    keywords = {type: article, mental health, conversational agents, artificial intelligence, chatbots, coping skills, resilience, psychological, depression, mHealth, emotions, empathy},
    abstract = {Background: A World Health Organization 2017 report stated that major depression affects almost 5% of the human population. Major depression is associated with impaired psychosocial functioning and reduced quality of life. Challenges such as shortage of mental health personnel, long waiting times, perceived stigma, and lower government spends pose barriers to the alleviation of mental health problems. Face-to-face psychotherapy alone provides only point-in-time support and cannot scale quickly enough to address this growing global public health challenge. Artificial intelligence (AI)-enabled, empathetic, and evidence-driven conversational mobile app technologies could play an active role in filling this gap by increasing adoption and enabling reach. Although such a technology can help manage these barriers, they should never replace time with a health care professional for more severe mental health problems. However, app technologies could act as a supplementary or intermediate support system. Mobile mental well-being apps need to uphold privacy and foster both short- and long-term positive outcomes. Objective: This study aimed to present a preliminary real-world data evaluation of the effectiveness and engagement levels of an AI-enabled, empathetic, text-based conversational mobile mental well-being app, Wysa, on users with self-reported symptoms of depression. Methods: In the study, a group of anonymous global users were observed who voluntarily installed the Wysa app, engaged in text-based messaging, and self-reported symptoms of depression using the Patient Health Questionnaire-9. On the basis of the extent of app usage on and between 2 consecutive screening time points, 2 distinct groups of users (high users and low users) emerged. The study used mixed-methods approach to evaluate the impact and engagement levels among these users. The quantitative analysis measured the app impact by comparing the average improvement in symptoms of depression between high and low users. The qualitative analysis measured the app engagement and experience by analyzing in-app user feedback and evaluated the performance of a machine learning classifier to detect user objections during conversations. Results: The average mood improvement (ie, difference in pre- and post-self-reported depression scores) between the groups (ie, high vs low users; n=108 and n=21, respectively) revealed that the high users group had significantly higher average improvement (mean 5.84 [SD 6.66]) compared with the low users group (mean 3.52 [SD 6.15]); Mann-Whitney P=.03 and with a moderate effect size of 0.63. Moreover, 67.7{\%} of user-provided feedback responses found the app experience helpful and encouraging. Conclusions: The real-world data evaluation findings on the effectiveness and engagement levels of Wysa app on users with self-reported symptoms of depression show promise. However, further work is required to validate these initial findings in much larger samples and across longer periods. },
    issn = {2291-5222},
    doi = {10.2196/12106},
    url = {http://mhealth.jmir.org/2018/11/e12106/},
    url = {https://doi.org/10.2196/12106},
    url = {http://www.ncbi.nlm.nih.gov/pubmed/30470676}
}

@article{Ly2017Automated,
    title = {A Fully Automated Conversational Agent for Promoting Mental Well-being: A pilot RCT Using Mixed Methods},
    journal = {Internet Interventions},
    references = {Fitzpatrick2017Cognitive},
    volume = {10},
    pages = {39-46},
    year = {2017},
    issn = {2214-7829},
    keywords = {type: Article },
    doi = {https://doi.org/10.1016/j.invent.2017.10.002},
    url = {https://www.sciencedirect.com/science/article/pii/S221478291730091X},
    author = {Kien Hoa Ly and Ann-Marie Ly and Gerhard Andersson},
    abstract = {Fully automated self-help interventions can serve as highly cost-effective mental health promotion tools for massive amounts of people. However, these interventions are often characterised by poor adherence. One way to address this problem is to mimic therapy support by a conversational agent. The objectives of this study were to assess the effectiveness and adherence of a smartphone app, delivering strategies used in positive psychology and CBT interventions via an automated chatbot (Shim) for a non-clinical population — as well as to explore participants' views and experiences of interacting with this chatbot. A total of 28 participants were randomized to either receive the chatbot intervention (n=14) or to a wait-list control group (n=14). Findings revealed that participants who adhered to the intervention (n=13) showed significant interaction effects of group and time on psychological well-being (FS) and perceived stress (PSS-10) compared to the wait-list control group, with small to large between effect sizes (Cohen's d range 0.14–1.06). Also, the participants showed high engagement during the 2-week long intervention, with an average open app ratio of 17.71 times for the whole period. This is higher compared to other studies on fully automated interventions claiming to be highly engaging, such as Woebot and the Panoply app. The qualitative data revealed sub-themes which, to our knowledge, have not been found previously, such as the moderating format of the chatbot. The results of this study, in particular the good adherence rate, validated the usefulness of replicating this study in the future with a larger sample size and an active control group. This is important, as the search for fully automated, yet highly engaging and effective digital self-help interventions for promoting mental health is crucial for the public health.}
}

@article{Palanica2019Physicians,
    author = {Palanica, Adam
and Flaschner, Peter
and Thommandram, Anirudh
and Li, Michael
and Fossat, Yan},
    title = {Physicians' Perceptions of Chatbots in Health Care: Cross-Sectional Web-Based Survey},
    journal = {J Med Internet Res},
    references = {Inkster2018Empathy Fulmer2018Psychological Fitzpatrick2017Cognitive},
    year = {2019},
    month = {Apr},
    day = {05},
    volume = {21},
    number = {4},
    pages = {e12887},
    keywords = {type: Article, physician satisfaction, health care, telemedicine, mobile health, health surveys},
    abstract = {Background: Many potential benefits for the uses of chatbots within the context of health care have been theorized, such as improved patient education and treatment compliance. However, little is known about the perspectives of practicing medical physicians on the use of chatbots in health care, even though these individuals are the traditional benchmark of proper patient care. Objective: This study aimed to investigate the perceptions of physicians regarding the use of health care chatbots, including their benefits, challenges, and risks to patients. Methods: A total of 100 practicing physicians across the United States completed a Web-based, self-report survey to examine their opinions of chatbot technology in health care. Descriptive statistics and frequencies were used to examine the characteristics of participants. Results: A wide variety of positive and negative perspectives were reported on the use of health care chatbots, including the importance to patients for managing their own health and the benefits on physical, psychological, and behavioral health outcomes. More consistent agreement occurred with regard to administrative benefits associated with chatbots; many physicians believed that chatbots would be most beneficial for scheduling doctor appointments (78{\%}, 78/100), locating health clinics (76{\%}, 76/100), or providing medication information (71{\%}, 71/100). Conversely, many physicians believed that chatbots cannot effectively care for all of the patients' needs (76{\%}, 76/100), cannot display human emotion (72{\%}, 72/100), and cannot provide detailed diagnosis and treatment because of not knowing all of the personal factors associated with the patient (71{\%}, 71/100). Many physicians also stated that health care chatbots could be a risk to patients if they self-diagnose too often (714{\%}, 74/100) and do not accurately understand the diagnoses (74{\%}, 74/100). Conclusions: Physicians believed in both costs and benefits associated with chatbots, depending on the logistics and specific roles of the technology. Chatbots may have a beneficial role to play in health care to support, motivate, and coach patients as well as for streamlining organizational tasks; in essence, chatbots could become a surrogate for nonmedical caregivers. However, concerns remain on the inability of chatbots to comprehend the emotional state of humans as well as in areas where expert medical knowledge and intelligence is required. },
    issn = {1438-8871},
    doi = {10.2196/12887},
    url = {https://www.jmir.org/2019/4/e12887/},
    url = {https://doi.org/10.2196/12887},
    url = {http://www.ncbi.nlm.nih.gov/pubmed/30950796}
}

@article{Vaidyam2019Chatbots,
    author = {Aditya Nrusimha Vaidyam and Hannah Wisniewski and John David Halamka and Matcheri S. Kashavan and John Blake Torous},
    title = {Chatbots and Conversational Agents in Mental Health: A Review of the Psychiatric Landscape},
    journal = {The Canadian Journal of Psychiatry},
    references = {Ly2017Automated Fitzpatrick2017Cognitive},
    volume = {64},
    number = {7},
    pages = {456-464},
    year = {2019},
    doi = {10.1177/0706743719828977},
    note = {PMID: 30897957},
    keywords = {type: Article },
    URL = {https://doi.org/10.1177/0706743719828977},
    eprint = {https://doi.org/10.1177/0706743719828977},
    abstract = { Objective: The aim of this review was to explore the current evidence for conversational agents or chatbots in the field of psychiatry and their role in screening, diagnosis, and treatment of mental illnesses.Methods: A systematic literature search in June 2018 was conducted in PubMed, EmBase, PsycINFO, Cochrane, Web of Science, and IEEE Xplore. Studies were included that involved a chatbot in a mental health setting focusing on populations with or at high risk of developing depression, anxiety, schizophrenia, bipolar, and substance abuse disorders.Results: From the selected databases, 1466 records were retrieved and 8 studies met the inclusion criteria. Two additional studies were included from reference list screening for a total of 10 included studies. Overall, potential for conversational agents in psychiatric use was reported to be high across all studies. In particular, conversational agents showed potential for benefit in psychoeducation and self-adherence. In addition, satisfaction rating of chatbots was high across all studies, suggesting that they would be an effective and enjoyable tool in psychiatric treatment.Conclusion: Preliminary evidence for psychiatric use of chatbots is favourable. However, given the heterogeneity of the reviewed studies, further research with standardized outcomes reporting is required to more thoroughly examine the effectiveness of conversational agents. Regardless, early evidence shows that with the proper approach and research, the mental health field could use conversational agents in psychiatric treatment. }
}