define({ entries : {
    "Abd-Alrazaq2019Overview": {
        "abstract": "Background Chatbots are systems that are able to converse and interact with human users using spoken, written, and visual languages. Chatbots have the potential to be useful tools for individuals with mental disorders, especially those who are reluctant to seek mental health advice due to stigmatization. While numerous studies have been conducted about using chatbots for mental health, there is a need to systematically bring this evidence together in order to inform mental health providers and potential users about the main features of chatbots and their potential uses, and to inform future research about the main gaps of the previous literature. Objective We aimed to provide an overview of the features of chatbots used by individuals for their mental health as reported in the empirical literature. Methods Seven bibliographic databases (Medline, Embase, PsycINFO, Cochrane Central Register of Controlled Trials, IEEE Xplore, ACM Digital Library, and Google Scholar) were used in our search. In addition, backward and forward reference list checking of the included studies and relevant reviews was conducted. Study selection and data extraction were carried out by two reviewers independently. Extracted data were synthesised using a narrative approach. Chatbots were classified according to their purposes, platforms, response generation, dialogue initiative, input and output modalities, embodiment, and targeted disorders. Results",
        "author": "Abd-Alrazaq, Alaa Ali and Alajlani, Mohannad and Alalwan, Ali Abdallah and Bewick, Bridgette M and Gardner, Peter and Househ, Mowafa",
        "doi": "https://doi.org/10.1016/j.ijmedinf.2019.103978",
        "issn": "1386-5056",
        "journal": "International Journal of Medical Informatics",
        "keywords": "type: Article, Chatbots, Conversational agents, Mental health, Mental disorders, Depression",
        "of 1039 citations retrieved, 53 unique studies were included in this review. the included studies assessed 41 different chatbots. common uses of chatbots were: therapy (n": "17), training (n Conclusion Research regarding chatbots in mental health is nascent. There are numerous chatbots that are used for various mental disorders and purposes. Healthcare providers should compare chatbots found in this review to help guide potential users to the most appropriate chatbot to support their mental health needs. More reviews are needed to summarise the evidence regarding the effectiveness and acceptability of chatbots in mental health.",
        "pages": "103978",
        "references": "Vaidyam2019Chatbots Inkster2018Empathy Fitzpatrick2017Cognitive",
        "title": "An Overview of the Features of Chatbots in Mental Health: A scoping Review",
        "type": "article",
        "url": "https://www.sciencedirect.com/science/article/pii/S1386505619307166",
        "volume": "132",
        "year": "2019"
    },
    "Abd-Alrazaq2020Effectiveness": {
        "abstract": "Background: The global shortage of mental health workers has prompted the utilization of technological advancements, such as chatbots, to meet the needs of people with mental health conditions. Chatbots are systems that are able to converse and interact with human users using spoken, written, and visual language. While numerous studies have assessed the effectiveness and safety of using chatbots in mental health, no reviews have pooled the results of those studies. Objective: This study aimed to assess the effectiveness and safety of using chatbots to improve mental health through summarizing and pooling the results of previous studies. Methods: A systematic review was carried out to achieve this objective. The search sources were 7 bibliographic databases (eg, MEDLINE, EMBASE, PsycINFO), the search engine ``Google Scholar,'' and backward and forward reference list checking of the included studies and relevant reviews. Two reviewers independently selected the studies, extracted data from the included studies, and assessed the risk of bias. Data extracted from studies were synthesized using narrative and statistical methods, as appropriate. Results: Of 1048 citations retrieved, we identified 12 studies examining the effect of using chatbots on 8 outcomes. Weak evidence demonstrated that chatbots were effective in improving depression, distress, stress, and acrophobia. In contrast, according to similar evidence, there was no statistically significant effect of using chatbots on subjective psychological wellbeing. Results were conflicting regarding the effect of chatbots on the severity of anxiety and positive and negative affect. Only two studies assessed the safety of chatbots and concluded that they are safe in mental health, as no adverse events or harms were reported. Conclusions: Chatbots have the potential to improve mental health. However, the evidence in this review was not sufficient to definitely conclude this due to lack of evidence that their effect is clinically important, a lack of studies assessing each outcome, high risk of bias in those studies, and conflicting results for some outcomes. Further studies are required to draw solid conclusions about the effectiveness and safety of chatbots. Trial Registration: PROSPERO International Prospective Register of Systematic Reviews CRD42019141219; https://www.crd.york.ac.uk/prospero/display{\\_}record.php?ID",
        "author": "Abd-Alrazaq, Alaa Ali and Rababeh, Asma and Alajlani, Mohannad and Bewick, Bridgette M and Househ, Mowafa",
        "day": "13",
        "doi": "10.2196/16021",
        "issn": "1438-8871",
        "journal": "J Med Internet Res",
        "keywords": "type: Article, Chatbots, conversational agents, mental health, mental disorders, depression, anxiety, effectiveness, safety",
        "month": "Jul",
        "number": "7",
        "pages": "e16021",
        "references": "Abd-Alrazaq2019Overview Vaidyam2019Chatbots Palanica2019Physicians Inkster2018Empathy Fulmer2018Psychological Ly2017Automated Fitzpatrick2017Cognitive",
        "title": "Effectiveness and Safety of Using Chatbots to Improve Mental Health: Systematic Review and Meta-Analysis",
        "type": "article",
        "url": "http://www.jmir.org/2020/7/e16021/ https://doi.org/10.2196/16021 http://www.ncbi.nlm.nih.gov/pubmed/32673216",
        "volume": "22",
        "year": "2020"
    },
    "Bendig2018Interventions": {
        "abstract": "Background: Clinical guidelines recommend psychosocial care as an integral part of medical treatment, but access is often limited. Technology-based approaches provide an attractive opportunity to optimize health outcomes and quality of life in people with chronic somatic diseases e.g. by means of Internet- and mobile-based interventions (IMIs). The present article provides an overview on the basics of IMIs, applications and their evidence base for people living with chronic somatic diseases.Methods: We conducted a selective literature search in the PubMed and Cochrane databases. Reviews which included randomized controlled trials investigating psychological IMIs were discussed pertaining to their relevance for the population described.Results: IMIs lead to a change in unfavorable behavior connected to chronic somatic diseases. IMIs can foster protective factors like balanced physical activity or risk factors like smoking or alcohol consumption. However, studies reveal small effect sizes of d",
        "author": "Bendig, Eileen and Bauerei\u00df, Natalie and Ebert, David Daniel and Snoek, Frank and Andersson, Gerhard and Baumeister, Harald",
        "doi": "10.3238/arztebl.2018.0659",
        "eprint": "https://www.aerzteblatt.de/pdf.asp?id",
        "journal": "Dtsch Arztebl International",
        "keywords": "type: Article",
        "number": "40",
        "pages": "659-665",
        "title": "{Internet-Based Interventions in Chronic Somatic Disease}",
        "type": "article",
        "url": "https://www.aerzteblatt.de/int/article.asp?id",
        "volume": "115",
        "year": "2018"
    },
    "Fitzpatrick2017Cognitive": {
        "abstract": "Background: Web-based cognitive-behavioral therapeutic (CBT) apps have demonstrated efficacy but are characterized by poor adherence. Conversational agents may offer a convenient, engaging way of getting support at any time. Objective: The objective of the study was to determine the feasibility, acceptability, and preliminary efficacy of a fully automated conversational agent to deliver a self-help program for college students who self-identify as having symptoms of anxiety and depression. Methods: In an unblinded trial, 70 individuals age 18-28 years were recruited online from a university community social media site and were randomized to receive either 2 weeks (up to 20 sessions) of self-help content derived from CBT principles in a conversational format with a text-based conversational agent (Woebot) (n",
        "author": "Fitzpatrick, Kathleen Kara and Darcy, Alison and Vierhile, Molly",
        "day": "06",
        "doi": "10.2196/mental.7785",
        "issn": "2368-7959",
        "journal": "JMIR Ment Health",
        "keywords": "type: article, conversational agents, mobile mental health, mental health, chatbots, depression, anxiety, college students, digital health",
        "month": "Jun",
        "number": "2",
        "pages": "e19",
        "title": "Delivering Cognitive Behavior Therapy to Young Adults With Symptoms of Depression and Anxiety Using a Fully Automated Conversational Agent (Woebot): A Randomized Controlled Trial",
        "type": "article",
        "url": "http://mental.jmir.org/2017/2/e19/ https://doi.org/10.2196/mental.7785 http://www.ncbi.nlm.nih.gov/pubmed/28588005",
        "volume": "4",
        "year": "2017"
    },
    "Fulmer2018Psychological": {
        "abstract": "Background: Students in need of mental health care face many barriers including cost, location, availability, and stigma. Studies show that computer-assisted therapy and 1 conversational chatbot delivering cognitive behavioral therapy (CBT) offer a less-intensive and more cost-effective alternative for treating depression and anxiety. Although CBT is one of the most effective treatment methods, applying an integrative approach has been linked to equally effective posttreatment improvement. Integrative psychological artificial intelligence (AI) offers a scalable solution as the demand for affordable, convenient, lasting, and secure support grows. Objective: This study aimed to assess the feasibility and efficacy of using an integrative psychological AI, Tess, to reduce self-identified symptoms of depression and anxiety in college students. Methods: In this randomized controlled trial, 75 participants were recruited from 15 universities across the United States. All participants completed Web-based surveys, including the Patient Health Questionnaire (PHQ-9), Generalized Anxiety Disorder Scale (GAD-7), and Positive and Negative Affect Scale (PANAS) at baseline and 2 to 4 weeks later (T2). The 2 test groups consisted of 50 participants in total and were randomized to receive unlimited access to Tess for either 2 weeks (n",
        "author": "Fulmer, Russell and Joerin, Angela and Gentile, Breanna and Lakerink, Lysanne and Rauws, Michiel",
        "day": "13",
        "doi": "10.2196/mental.9782",
        "issn": "2368-7959",
        "journal": "JMIR Ment Health",
        "keywords": "type: article, artificial intelligence, mental health services, depression, anxiety, students",
        "month": "Dec",
        "number": "4",
        "pages": "e64",
        "references": "Fitzpatrick2017Cognitive",
        "title": "Using Psychological Artificial Intelligence (Tess) to Relieve Symptoms of Depression and Anxiety: Randomized Controlled Trial",
        "type": "article",
        "url": "http://mental.jmir.org/2018/4/e64/ https://doi.org/10.2196/mental.9782 http://www.ncbi.nlm.nih.gov/pubmed/30545815",
        "volume": "5",
        "year": "2018"
    },
    "Gaffney2019Conversational": {
        "abstract": "Background: The use of conversational agent interventions (including chatbots and robots) in mental health is growing at a fast pace. Recent existing reviews have focused exclusively on a subset of embodied conversational agent interventions despite other modalities aiming to achieve the common goal of improved mental health. Objective: This study aimed to review the use of conversational agent interventions in the treatment of mental health problems. Methods: We performed a systematic search using relevant databases (MEDLINE, EMBASE, PsycINFO, Web of Science, and Cochrane library). Studies that reported on an autonomous conversational agent that simulated conversation and reported on a mental health outcome were included. Results: A total of 13 studies were included in the review. Among them, 4 full-scale randomized controlled trials (RCTs) were included. The rest were feasibility, pilot RCTs and quasi-experimental studies. Interventions were diverse in design and targeted a range of mental health problems using a wide variety of therapeutic orientations. All included studies reported reductions in psychological distress postintervention. Furthermore, 5 controlled studies demonstrated significant reductions in psychological distress compared with inactive control groups. In addition, 3 controlled studies comparing interventions with active control groups failed to demonstrate superior effects. Broader utility in promoting well-being in nonclinical populations was unclear. Conclusions: The efficacy and acceptability of conversational agent interventions for mental health problems are promising. However, a more robust experimental design is required to demonstrate efficacy and efficiency. A focus on streamlining interventions, demonstrating equivalence to other treatment modalities, and elucidating mechanisms of action has the potential to increase acceptance by users and clinicians and maximize reach.",
        "author": "Gaffney, Hannah and Mansell, Warren and Tai, Sara",
        "day": "18",
        "doi": "10.2196/14166",
        "issn": "2368-7959",
        "journal": "JMIR Ment Health",
        "keywords": "type: article, artificial intelligence, mental health, stress, pychological, psychiatry, therapy, computer-assisted conversational agent, chatbot, digital health",
        "month": "Oct",
        "number": "10",
        "pages": "e14166",
        "references": "Inkster2018Empathy Fulmer2018Psychological Ly2017Automated Fitzpatrick2017Cognitive",
        "title": "Conversational Agents in the Treatment of Mental Health Problems: Mixed-Method Systematic Review",
        "type": "article",
        "url": "https://mental.jmir.org/2019/10/e14166 https://doi.org/10.2196/14166 http://www.ncbi.nlm.nih.gov/pubmed/31628789",
        "volume": "6",
        "year": "2019"
    },
    "Inkster2018Empathy": {
        "abstract": "Background: A World Health Organization 2017 report stated that major depression affects almost 5% of the human population. Major depression is associated with impaired psychosocial functioning and reduced quality of life. Challenges such as shortage of mental health personnel, long waiting times, perceived stigma, and lower government spends pose barriers to the alleviation of mental health problems. Face-to-face psychotherapy alone provides only point-in-time support and cannot scale quickly enough to address this growing global public health challenge. Artificial intelligence (AI)-enabled, empathetic, and evidence-driven conversational mobile app technologies could play an active role in filling this gap by increasing adoption and enabling reach. Although such a technology can help manage these barriers, they should never replace time with a health care professional for more severe mental health problems. However, app technologies could act as a supplementary or intermediate support system. Mobile mental well-being apps need to uphold privacy and foster both short- and long-term positive outcomes. Objective: This study aimed to present a preliminary real-world data evaluation of the effectiveness and engagement levels of an AI-enabled, empathetic, text-based conversational mobile mental well-being app, Wysa, on users with self-reported symptoms of depression. Methods: In the study, a group of anonymous global users were observed who voluntarily installed the Wysa app, engaged in text-based messaging, and self-reported symptoms of depression using the Patient Health Questionnaire-9. On the basis of the extent of app usage on and between 2 consecutive screening time points, 2 distinct groups of users (high users and low users) emerged. The study used mixed-methods approach to evaluate the impact and engagement levels among these users. The quantitative analysis measured the app impact by comparing the average improvement in symptoms of depression between high and low users. The qualitative analysis measured the app engagement and experience by analyzing in-app user feedback and evaluated the performance of a machine learning classifier to detect user objections during conversations. Results: The average mood improvement (ie, difference in pre- and post-self-reported depression scores) between the groups (ie, high vs low users; n",
        "author": "Inkster, Becky and Sarda, Shubhankar and Subramanian, Vinod",
        "day": "23",
        "doi": "10.2196/12106",
        "issn": "2291-5222",
        "journal": "JMIR Mhealth Uhealth",
        "keywords": "type: article, mental health, conversational agents, artificial intelligence, chatbots, coping skills, resilience, psychological, depression, mHealth, emotions, empathy",
        "month": "Nov",
        "number": "11",
        "pages": "e12106",
        "references": "Ly2017Automated Fitzpatrick2017Cognitive",
        "title": "An Empathy-Driven, Conversational Artificial Intelligence Agent (Wysa) for Digital Mental Well-Being: Real-World Data Evaluation Mixed-Methods Study",
        "type": "article",
        "url": "http://mhealth.jmir.org/2018/11/e12106/ https://doi.org/10.2196/12106 http://www.ncbi.nlm.nih.gov/pubmed/30470676",
        "volume": "6",
        "year": "2018"
    },
    "Ly2017Automated": {
        "abstract": "Fully automated self-help interventions can serve as highly cost-effective mental health promotion tools for massive amounts of people. However, these interventions are often characterised by poor adherence. One way to address this problem is to mimic therapy support by a conversational agent. The objectives of this study were to assess the effectiveness and adherence of a smartphone app, delivering strategies used in positive psychology and CBT interventions via an automated chatbot (Shim) for a non-clinical population \u2014 as well as to explore participants' views and experiences of interacting with this chatbot. A total of 28 participants were randomized to either receive the chatbot intervention (n",
        "author": "Kien Hoa Ly and Ann-Marie Ly and Gerhard Andersson",
        "doi": "https://doi.org/10.1016/j.invent.2017.10.002",
        "issn": "2214-7829",
        "journal": "Internet Interventions",
        "keywords": "type: Article",
        "pages": "39-46",
        "references": "Fitzpatrick2017Cognitive",
        "title": "A Fully Automated Conversational Agent for Promoting Mental Well-being: A pilot RCT Using Mixed Methods",
        "type": "article",
        "url": "https://www.sciencedirect.com/science/article/pii/S221478291730091X",
        "volume": "10",
        "year": "2017"
    },
    "Palanica2019Physicians": {
        "abstract": "Background: Many potential benefits for the uses of chatbots within the context of health care have been theorized, such as improved patient education and treatment compliance. However, little is known about the perspectives of practicing medical physicians on the use of chatbots in health care, even though these individuals are the traditional benchmark of proper patient care. Objective: This study aimed to investigate the perceptions of physicians regarding the use of health care chatbots, including their benefits, challenges, and risks to patients. Methods: A total of 100 practicing physicians across the United States completed a Web-based, self-report survey to examine their opinions of chatbot technology in health care. Descriptive statistics and frequencies were used to examine the characteristics of participants. Results: A wide variety of positive and negative perspectives were reported on the use of health care chatbots, including the importance to patients for managing their own health and the benefits on physical, psychological, and behavioral health outcomes. More consistent agreement occurred with regard to administrative benefits associated with chatbots; many physicians believed that chatbots would be most beneficial for scheduling doctor appointments (78{\\% 78/100), locating health clinics (76{\\% 76/100), or providing medication information (71{\\% 71/100). Conversely, many physicians believed that chatbots cannot effectively care for all of the patients' needs (76{\\% 76/100), cannot display human emotion (72{\\% 72/100), and cannot provide detailed diagnosis and treatment because of not knowing all of the personal factors associated with the patient (71{\\% 71/100). Many physicians also stated that health care chatbots could be a risk to patients if they self-diagnose too often (714{\\% 74/100) and do not accurately understand the diagnoses (74{\\% 74/100). Conclusions: Physicians believed in both costs and benefits associated with chatbots, depending on the logistics and specific roles of the technology. Chatbots may have a beneficial role to play in health care to support, motivate, and coach patients as well as for streamlining organizational tasks; in essence, chatbots could become a surrogate for nonmedical caregivers. However, concerns remain on the inability of chatbots to comprehend the emotional state of humans as well as in areas where expert medical knowledge and intelligence is required.",
        "author": "Palanica, Adam and Flaschner, Peter and Thommandram, Anirudh and Li, Michael and Fossat, Yan",
        "day": "05",
        "doi": "10.2196/12887",
        "issn": "1438-8871",
        "journal": "J Med Internet Res",
        "keywords": "type: Article, physician satisfaction, health care, telemedicine, mobile health, health surveys",
        "month": "Apr",
        "number": "4",
        "pages": "e12887",
        "references": "Inkster2018Empathy Fulmer2018Psychological Fitzpatrick2017Cognitive",
        "title": "Physicians' Perceptions of Chatbots in Health Care: Cross-Sectional Web-Based Survey",
        "type": "article",
        "url": "https://www.jmir.org/2019/4/e12887/ https://doi.org/10.2196/12887 http://www.ncbi.nlm.nih.gov/pubmed/30950796",
        "volume": "21",
        "year": "2019"
    },
    "Vaidyam2019Chatbots": {
        "abstract": " Objective: The aim of this review was to explore the current evidence for conversational agents or chatbots in the field of psychiatry and their role in screening, diagnosis, and treatment of mental illnesses.Methods: A systematic literature search in June 2018 was conducted in PubMed, EmBase, PsycINFO, Cochrane, Web of Science, and IEEE Xplore. Studies were included that involved a chatbot in a mental health setting focusing on populations with or at high risk of developing depression, anxiety, schizophrenia, bipolar, and substance abuse disorders.Results: From the selected databases, 1466 records were retrieved and 8 studies met the inclusion criteria. Two additional studies were included from reference list screening for a total of 10 included studies. Overall, potential for conversational agents in psychiatric use was reported to be high across all studies. In particular, conversational agents showed potential for benefit in psychoeducation and self-adherence. In addition, satisfaction rating of chatbots was high across all studies, suggesting that they would be an effective and enjoyable tool in psychiatric treatment.Conclusion: Preliminary evidence for psychiatric use of chatbots is favourable. However, given the heterogeneity of the reviewed studies, further research with standardized outcomes reporting is required to more thoroughly examine the effectiveness of conversational agents. Regardless, early evidence shows that with the proper approach and research, the mental health field could use conversational agents in psychiatric treatment.",
        "author": "Aditya Nrusimha Vaidyam and Hannah Wisniewski and John David Halamka and Matcheri S. Kashavan and John Blake Torous",
        "doi": "10.1177/0706743719828977",
        "eprint": "https://doi.org/10.1177/0706743719828977",
        "journal": "The Canadian Journal of Psychiatry",
        "keywords": "type: Article",
        "note": "PMID: 30897957",
        "number": "7",
        "pages": "456-464",
        "references": "Ly2017Automated Fitzpatrick2017Cognitive",
        "title": "Chatbots and Conversational Agents in Mental Health: A Review of the Psychiatric Landscape",
        "type": "article",
        "url": "https://doi.org/10.1177/0706743719828977",
        "volume": "64",
        "year": "2019"
    }
}});